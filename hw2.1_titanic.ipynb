{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOMEWORK 2.1: Titanic ML Competition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%% \n"
    }
   },
   "outputs": [],
   "source": [
    "# Common imports\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.pipeline import Pipeline#This library is essential for constructing a sequence of data processing steps, #facilitating a clean and organized workflow in machine learning pipelines.\n",
    "from sklearn.impute import SimpleImputer#This library is used to handle missing values in the dataset by replacing them #with a specified strategy, such as the median or most frequent value.\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder#StandardScaler library  is necessary to standardize #numerical features, ensuring they have a mean of 0 and a standard deviation of 1, which is often important for machine #learning algorithms. OrdinalEncoder library  is employed to encode categorical features into numerical values, making #them suitable for input into machine learning models.\n",
    "from sklearn.svm import SVC#This library imports the Support Vector Classifier as it is a ML model commonly used\n",
    "# #for classification tasks.\n",
    "from sklearn.neighbors import KNeighborsClassifier#Imports the k-Nearest Neighbors classifier, a simple and effective #algorithm for classification based on nearest neighbors.\n",
    "from sklearn.ensemble import RandomForestClassifier#Imports the Random Forest classifier, an ensemble learning method #that combines multiple decision trees.\n",
    "from sklearn.model_selection import cross_val_score#Used for cross-validation, providing an efficient way to assess a #model's performance by splitting the data into multiple subsets and evaluating the model on each subset.\n",
    "from sklearn.metrics import accuracy_score#The metric used to measure the accuracy of a classification model by  #comparing the predicted labels to the true labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%% \n"
    }
   },
   "outputs": [],
   "source": [
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of HW2.1: Tackle the Titanic dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the legendary Titanic ML competition the best of [Kaggle](https://www.kaggle.com/), \n",
    "first challenge for you to dive into ML competitions and familiarize yourself with how the Kaggle platform works.\n",
    "Let's go to the [Titanic challenge](https://www.kaggle.com/c/titanic).\n",
    "\n",
    "The data is already split into a training set and a test set. However, the test data does *not* contain the labels: your goal is to train the best model you can using the training data, then make your predictions on the test data and REPORT your final score.\n",
    "\n",
    "The goal is to predict whether or not a passenger survived based on attributes such as their age, sex, passenger class, where they embarked and so on.\n",
    "\n",
    "Note: Students with the highest score on the assignment will be awarded an additional 10 points as an assignment score. \n",
    "All submitted scores will be ranked in descending order and the top 5 students will be awarded an additional +10 points. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"datasets/titanic/train.csv\")\n",
    "test_data = pd.read_csv(\"datasets/titanic/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a peek at the top few rows of the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n3            4         1       1   \n4            5         0       3   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                           Allen, Mr. William Henry    male  35.0      0   \n\n   Parch            Ticket     Fare Cabin Embarked  \n0      0         A/5 21171   7.2500   NaN        S  \n1      0          PC 17599  71.2833   C85        C  \n2      0  STON/O2. 3101282   7.9250   NaN        S  \n3      0            113803  53.1000  C123        S  \n4      0            373450   8.0500   NaN        S  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attributes have the following meaning:\n",
    "* **Survived**: that's the target, 0 means the passenger did not survive, while 1 means he/she survived.\n",
    "* **Pclass**: passenger class.\n",
    "* **Name**, **Sex**, **Age**: self-explanatory\n",
    "* **SibSp**: how many siblings & spouses of the passenger aboard the Titanic? // Titanik'te yolcunun kaç kardeşi ve eşi var?\n",
    "* **Parch**: how many children & parents of the passenger aboard the Titanic? // Titanik'te yolcunun kaç çocuğu ve ebeveyni var?\n",
    "* **Ticket**: ticket id\n",
    "* **Fare**: price paid (in pounds)\n",
    "* **Cabin**: passenger's cabin number\n",
    "* **Embarked**: where the passenger embarked the Titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get more info to see how much data is missing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, the **Age**, **Cabin** and **Embarked** attributes are sometimes null (less than 891 non-null),\n",
    " especially the **Cabin** (77% are null). \n",
    " We will ignore the **Cabin** for now and focus on the rest. \n",
    " The **Age** attribute has about 19% null values, \n",
    " so we will need to decide what to do with them. \n",
    " Replacing null values with the median age seems reasonable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Name** and **Ticket** attributes may have some value,\n",
    " but they will be a bit tricky to convert into useful numbers that a model can consume. \n",
    " So for now, we will ignore them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the numerical attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "       PassengerId    Survived      Pclass         Age       SibSp  \\\ncount   891.000000  891.000000  891.000000  714.000000  891.000000   \nmean    446.000000    0.383838    2.308642   29.699118    0.523008   \nstd     257.353842    0.486592    0.836071   14.526497    1.102743   \nmin       1.000000    0.000000    1.000000    0.420000    0.000000   \n25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n75%     668.500000    1.000000    3.000000   38.000000    1.000000   \nmax     891.000000    1.000000    3.000000   80.000000    8.000000   \n\n            Parch        Fare  \ncount  891.000000  891.000000  \nmean     0.381594   32.204208  \nstd      0.806057   49.693429  \nmin      0.000000    0.000000  \n25%      0.000000    7.910400  \n50%      0.000000   14.454200  \n75%      0.000000   31.000000  \nmax      6.000000  512.329200  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>714.000000</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>446.000000</td>\n      <td>0.383838</td>\n      <td>2.308642</td>\n      <td>29.699118</td>\n      <td>0.523008</td>\n      <td>0.381594</td>\n      <td>32.204208</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>257.353842</td>\n      <td>0.486592</td>\n      <td>0.836071</td>\n      <td>14.526497</td>\n      <td>1.102743</td>\n      <td>0.806057</td>\n      <td>49.693429</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.420000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>223.500000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>20.125000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>7.910400</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>446.000000</td>\n      <td>0.000000</td>\n      <td>3.000000</td>\n      <td>28.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>14.454200</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>668.500000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>38.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>31.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>891.000000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>80.000000</td>\n      <td>8.000000</td>\n      <td>6.000000</td>\n      <td>512.329200</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* only 38% **Survived**. :(  That's close enough to 40%, so accuracy will be a reasonable metric to evaluate our model.\n",
    "* The mean **Fare** was £32.20, which does not seem so expensive (but it was probably a lot of money back then).\n",
    "* The mean **Age** was less than 30 years old."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that the target is indeed 0 or 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0    549\n1    342\nName: Survived, dtype: int64"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"Survived\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a quick look at all the categorical attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "3    491\n1    216\n2    184\nName: Pclass, dtype: int64"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"Pclass\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "male      577\nfemale    314\nName: Sex, dtype: int64"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"Sex\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "S    644\nC    168\nQ     77\nName: Embarked, dtype: int64"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"Embarked\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Embarked attribute tells us where the passenger embarked: C=Cherbourg, Q=Queenstown, S=Southampton.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO-DO 2.1.1: Build your pre-processing pipelines for numerical/categorical attributes.\n",
    " - Use SimpleImputer for pre-processing. \n",
    " - Use \"Median\" Strategy for the SimpleImputer for numerical attributes\n",
    " - Use \"OrdinalEncoder\" function and \"most_frequent\" strategy for categorical attributes\n",
    " - Examine the changes that the simpleimpute function makes to the data and give examples of changed values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed Numerical Features:\n",
      "       Pclass       Age     SibSp     Parch      Fare\n",
      "0    0.827377 -0.565736  0.432793 -0.473674 -0.502445\n",
      "1   -1.566107  0.663861  0.432793 -0.473674  0.786845\n",
      "2    0.827377 -0.258337 -0.474545 -0.473674 -0.488854\n",
      "3   -1.566107  0.433312  0.432793 -0.473674  0.420730\n",
      "4    0.827377  0.433312 -0.474545 -0.473674 -0.486337\n",
      "..        ...       ...       ...       ...       ...\n",
      "886 -0.369365 -0.181487 -0.474545 -0.473674 -0.386671\n",
      "887 -1.566107 -0.796286 -0.474545 -0.473674 -0.044381\n",
      "888  0.827377 -0.104637  0.432793  2.008933 -0.176263\n",
      "889 -1.566107 -0.258337 -0.474545 -0.473674 -0.044381\n",
      "890  0.827377  0.202762 -0.474545 -0.473674 -0.492378\n",
      "\n",
      "[891 rows x 5 columns]\n",
      "\n",
      "Transformed Categorical Features:\n",
      "     Sex  Embarked\n",
      "0    1.0       2.0\n",
      "1    0.0       0.0\n",
      "2    0.0       2.0\n",
      "3    0.0       2.0\n",
      "4    1.0       2.0\n",
      "..   ...       ...\n",
      "886  1.0       2.0\n",
      "887  0.0       2.0\n",
      "888  0.0       2.0\n",
      "889  1.0       0.0\n",
      "890  1.0       1.0\n",
      "\n",
      "[891 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Separating numerical and categorical attributes\n",
    "numerical_features = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n",
    "#PassengerId feature is not included as it is an identifier and doesn't provide meaningful information for predicting #survival on its own.\n",
    "categorical_features = ['Sex', 'Embarked']\n",
    "\n",
    "# 2.1.1 - build the pipeline for the numerical attributes:\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),  # Impute missing values with the median\n",
    "    ('scaler', StandardScaler())  # Standardize numerical features\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# 2.1.1 - build the pipeline for the categorical attributes:\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),  # Impute missing values with the most frequent value\n",
    "    ('encoder', OrdinalEncoder())  # Encode categorical features\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# 2.1.1 - interpret results:\n",
    "# After fitting the pipelines to the data, you can transform the numerical and categorical features separately.\n",
    "# For example, if you have a DataFrame named 'train_data', you can apply the transformations as follows:\n",
    "\n",
    "# Apply numerical pipeline to numerical features\n",
    "X_train_num = num_pipeline.fit_transform(train_data[numerical_features])\n",
    "\n",
    "# Apply categorical pipeline to categorical features\n",
    "X_train_cat = cat_pipeline.fit_transform(train_data[categorical_features])\n",
    "\n",
    "# Display the transformed data\n",
    "print(\"Transformed Numerical Features:\")\n",
    "print(pd.DataFrame(X_train_num, columns=numerical_features))\n",
    "\n",
    "print(\"\\nTransformed Categorical Features:\")\n",
    "print(pd.DataFrame(X_train_cat, columns=categorical_features))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! Now we have a nice preprocessing pipeline that takes the raw data and outputs numerical input features that we can feed to any Machine Learning model we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "num_attribs = [\"Age\", \"SibSp\", \"Parch\", \"Fare\"]\n",
    "cat_attribs = [\"Pclass\", \"Sex\", \"Embarked\"]\n",
    "\n",
    "preprocess_pipeline = ColumnTransformer([\n",
    "        (\"num\", num_pipeline, num_attribs),\n",
    "        (\"cat\", cat_pipeline, cat_attribs),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-0.56573646,  0.43279337, -0.47367361, ...,  2.        ,\n         1.        ,  2.        ],\n       [ 0.66386103,  0.43279337, -0.47367361, ...,  0.        ,\n         0.        ,  0.        ],\n       [-0.25833709, -0.4745452 , -0.47367361, ...,  2.        ,\n         0.        ,  2.        ],\n       ...,\n       [-0.1046374 ,  0.43279337,  2.00893337, ...,  2.        ,\n         0.        ,  2.        ],\n       [-0.25833709, -0.4745452 , -0.47367361, ...,  0.        ,\n         1.        ,  0.        ],\n       [ 0.20276197, -0.4745452 , -0.47367361, ...,  2.        ,\n         1.        ,  1.        ]])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = preprocess_pipeline.fit_transform(train_data)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's not forget to get the labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_data[\"Survived\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to train a classifier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO-DO 2.1.2: Use Support a Classifier (SVC, KNN, RandomForest etc.) \n",
    " - Use 3 different Classifier (using sklearn library)\n",
    " - Train the selected classifer using \"train_data\" and \"y_train\" labels to classify/predict \"Survived Passanger\" for TEST DATA (test_data) \n",
    " - Use cross-validation method to get avarage accuracy for the dataset \n",
    "   (example: \n",
    "             from sklearn.model_selection import cross_val_score\n",
    "             clf1_scores = cross_val_score(clf1, X_train, y_train, cv=10)\n",
    "             clf1_scores.mean() \n",
    "             \n",
    " - Show the best prediction accuracy \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Average Accuracy: 0.8204494382022471\n",
      "KNN Average Accuracy: 0.7957553058676654\n",
      "Random Forest Average Accuracy: 0.8149063670411986\n",
      "Best Classifier: SVC with an average accuracy of 0.8204494382022471\n"
     ]
    }
   ],
   "source": [
    "# Load the test data from 'test.csv'\n",
    "test_data = pd.read_csv('/Users/atenaparsa/Downloads/datasets/titanic/test.csv')\n",
    "\n",
    "# Separating numerical and categorical attributes\n",
    "numerical_features = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n",
    "categorical_features = ['Sex', 'Embarked']\n",
    "\n",
    "# Build the pipeline for the numerical attributes\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Build the pipeline for the categorical attributes\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OrdinalEncoder())\n",
    "])\n",
    "\n",
    "# Combine pipelines\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_pipeline, numerical_features),\n",
    "        ('cat', cat_pipeline, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train = preprocessor.fit_transform(train_data)\n",
    "\n",
    "# Transform the test data\n",
    "X_test = preprocessor.transform(test_data)\n",
    "\n",
    "# Initialize classifiers\n",
    "clf_svc = SVC()\n",
    "clf_knn = KNeighborsClassifier()\n",
    "clf_rf = RandomForestClassifier()\n",
    "\n",
    "# 2.1.2 - Classifier 1 - Support Vector Classifier\n",
    "# Train classifier and make predictions\n",
    "clf_svc.fit(X_train, y_train)\n",
    "y_pred_svc = clf_svc.predict(X_test)\n",
    "\n",
    "# 2.1.2 - Classifier 2 - KNeighbors\n",
    "# Train classifier and make predictions\n",
    "clf_knn.fit(X_train, y_train)\n",
    "y_pred_knn = clf_knn.predict(X_test)\n",
    "\n",
    "# 2.1.2 - Classifier 3 - Random Forest\n",
    "# Train classifier and make predictions\n",
    "clf_rf.fit(X_train, y_train)\n",
    "y_pred_rf = clf_rf.predict(X_test)\n",
    "\n",
    "# 2.1.2 - Write your the BEST Accuracy\n",
    "# Cross-validation to get average accuracy\n",
    "svc_scores = cross_val_score(clf_svc, X_train, y_train, cv=10)\n",
    "knn_scores = cross_val_score(clf_knn, X_train, y_train, cv=10)\n",
    "rf_scores = cross_val_score(clf_rf, X_train, y_train, cv=10)\n",
    "\n",
    "# Display average accuracy for each classifier\n",
    "print(\"SVC Average Accuracy:\", svc_scores.mean())\n",
    "print(\"KNN Average Accuracy:\", knn_scores.mean())\n",
    "print(\"Random Forest Average Accuracy:\", rf_scores.mean())\n",
    "\n",
    "# Identify the best classifier based on the highest accuracy\n",
    "best_classifier = max([(svc_scores.mean(), 'SVC'), (knn_scores.mean(), 'KNN'), (rf_scores.mean(), 'Random Forest')])\n",
    "print(\"Best Classifier:\", best_classifier[1], \"with an average accuracy of\", best_classifier[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
